{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a4e491-847b-4d3d-b9d2-81550d208218",
   "metadata": {},
   "source": [
    "In this notebook we compute BERT embeddings of text and apply clustering to these embeddings. <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b8f1aee-0b81-4a1a-b6c9-a5003dd564e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb95292-4a4d-4133-9d54-f8c4761cc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c560f01e-b7af-48c4-8116-08f0a45e0b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskId</th>\n",
       "      <th>language</th>\n",
       "      <th>description</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9oqJmtbKXts6Rr9Szw4OIS</td>\n",
       "      <td>eng</td>\n",
       "      <td>What are the courses that clients can book at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a0pzxEfKq8c9D0dRZlQcm9</td>\n",
       "      <td>eng</td>\n",
       "      <td>Write a rule for astronauts. Use a conditional...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9Hjn2yUwBcs7DZK6HARkE4</td>\n",
       "      <td>eng</td>\n",
       "      <td>Can you guess the most frequently spoken langu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6AYw9CEZMTN7LN8u0LfYVb</td>\n",
       "      <td>eng</td>\n",
       "      <td>Complete the sentence with going to. Example: ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8QIKtMOE9zV6lnfc2vHMUd</td>\n",
       "      <td>eng</td>\n",
       "      <td>The following are examples of vegetables. carr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   taskId language  \\\n",
       "0  9oqJmtbKXts6Rr9Szw4OIS      eng   \n",
       "1  a0pzxEfKq8c9D0dRZlQcm9      eng   \n",
       "2  9Hjn2yUwBcs7DZK6HARkE4      eng   \n",
       "3  6AYw9CEZMTN7LN8u0LfYVb      eng   \n",
       "4  8QIKtMOE9zV6lnfc2vHMUd      eng   \n",
       "\n",
       "                                         description  topic_id  word_count  \n",
       "0  What are the courses that clients can book at ...       NaN          12  \n",
       "1  Write a rule for astronauts. Use a conditional...       NaN          43  \n",
       "2  Can you guess the most frequently spoken langu...       NaN          22  \n",
       "3  Complete the sentence with going to. Example: ...       NaN          42  \n",
       "4  The following are examples of vegetables. carr...       NaN          16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data \n",
    "df = pd.read_csv(\"data/all_augmented_tasks_EN.csv\") \n",
    "df = df.dropna(subset=[\"description\"])\n",
    "df = df[df[\"word_count\"] > 4] # removing test descriptions # TODO move to data cleaning steps\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb887dfe-b47d-4a4c-ac7d-911112a26661",
   "metadata": {},
   "source": [
    "> **Distribution of words:** Refer to 4_concat_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42af255b-6b41-4754-9825-7efb7bd087d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspectId</th>\n",
       "      <th>sampleSolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5ElPCuVMbAy8pzupzU7R3x</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>2VX1HHa4SZp9Cs6Suof4ho</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2j6rJkYxYa98ydGaSCW17D</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>2j6rJkYxYa98ydGaSCW17D</td>\n",
       "      <td>20</td>\n",
       "      <td>{\"type\": \"DEFAULT\", \"sampleSolutionGroups\": [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>2j6rJkYxYa98ydGaSCW17D</td>\n",
       "      <td>21</td>\n",
       "      <td>{\"type\": \"DEFAULT\", \"sampleSolutionGroups\": [{...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  taskId  aspectId  \\\n",
       "0   3  5ElPCuVMbAy8pzupzU7R3x         2   \n",
       "1  54  2VX1HHa4SZp9Cs6Suof4ho         1   \n",
       "2  74  2j6rJkYxYa98ydGaSCW17D         4   \n",
       "3  75  2j6rJkYxYa98ydGaSCW17D        20   \n",
       "4  76  2j6rJkYxYa98ydGaSCW17D        21   \n",
       "\n",
       "                                      sampleSolution  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3  {\"type\": \"DEFAULT\", \"sampleSolutionGroups\": [{...  \n",
       "4  {\"type\": \"DEFAULT\", \"sampleSolutionGroups\": [{...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnx = mysql.connector.connect(user='root', password='taskbase',\n",
    "                              host='127.0.0.1', port='3309', database='lernnavi')\n",
    "\n",
    "query = \"SELECT * FROM TaskAspects\"\n",
    "df_taskAspects = pd.read_sql(query, cnx)\n",
    "df_taskAspects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d523f13b-3f38-4a18-bac6-f7e06258f985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>aspectId</th>\n",
       "      <th>description</th>\n",
       "      <th>4</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>47</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>74</th>\n",
       "      <th>...</th>\n",
       "      <th>272853</th>\n",
       "      <th>272854</th>\n",
       "      <th>272882</th>\n",
       "      <th>272883</th>\n",
       "      <th>272887</th>\n",
       "      <th>272888</th>\n",
       "      <th>272894</th>\n",
       "      <th>272895</th>\n",
       "      <th>272900</th>\n",
       "      <th>272901</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Climate change is a dangerous threat,\" he said.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "aspectId                                       description      4     20  \\\n",
       "0         \"Climate change is a dangerous threat,\" he said.  False  False   \n",
       "\n",
       "aspectId     21     47     69     70     71     72     74  ...  272853  \\\n",
       "0         False  False  False  False  False  False  False  ...   False   \n",
       "\n",
       "aspectId  272854  272882  272883  272887  272888  272894  272895  272900  \\\n",
       "0          False   False   False   False   False   False   False   False   \n",
       "\n",
       "aspectId  272901  \n",
       "0          False  \n",
       "\n",
       "[1 rows x 1462 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attribute labels (aspectId) to descriptions\n",
    "df = pd.merge(df[[\"taskId\", \"description\"]], df_taskAspects[[\"taskId\", \"aspectId\"]], how=\"inner\", on=[\"taskId\"]) \n",
    "df_pivot = df.pivot_table(index='description', columns='aspectId', aggfunc='size', fill_value=None)\n",
    "df_pivot = df_pivot.notnull().reset_index()\n",
    "df_pivot.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9925c3-87cb-4539-a1ca-bc41168d6075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataset \n",
    "dataset = Dataset.from_pandas(df_pivot) \n",
    "\n",
    "# Make splits: train, test, validation\n",
    "train_test = dataset.train_test_split(test_size=0.3)\n",
    "test_val = train_test[\"test\"].train_test_split(test_size=0.33)\n",
    "\n",
    "# Recreate Dataset with the three splits \n",
    "data = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'test': test_val['train'],\n",
    "    'validation': test_val['test']\n",
    "})\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d4f3c3-2f0d-47d6-a2fe-e0617c4618b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843, 242, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['train']), len(data['test']), len(data['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9338a7e8-68b8-4aec-a607-def937eb4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label for label in data['train'].features.keys() if label not in ['description']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdebd9-c7f5-4ecb-950b-66ba52b4487d",
   "metadata": {},
   "source": [
    "# Training BERT-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e8bc90-158b-4204-9582-9c5ccbe3df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1507b-a327-4a70-b6c3-23f14b4d57c9",
   "metadata": {},
   "source": [
    "**Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23ec55a-41a0-4145-99ab-3e03619c61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac625d8-b068-48a3-945c-15754e66010e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5d7c57eca24dcc9e4a7188c8269172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/843 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9eb17f37854f80ad61650aacd417c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b33aab43e3420a819c33c16bf67d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing \n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"description\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  return encoding\n",
    "\n",
    "encoded_dataset = data.map(preprocess_data, batched=True, remove_columns=data['train'].column_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bb638e4-b95c-45c6-aa04-7529367dc584",
   "metadata": {},
   "source": [
    "example = encoded_dataset['train'][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b9ada82-1594-4a40-8115-e7885644a49a",
   "metadata": {},
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5025c0e-b426-4bbb-8618-10976dba89c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "example['labels']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5f08b4a-7051-461c-9d92-6a80a42f777e",
   "metadata": {},
   "source": [
    "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53e019b7-a09c-4d84-9369-a16cbf1ae8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf649e-df6d-433d-aaa8-495b92ea81a6",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b170ace-cf80-4dd0-9ba3-0e2dc1d53ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41de402a-fb23-4b3a-8936-74262b0970f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "metric_name = \"f1\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"bert-finetuned-sem_eval-english\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-8,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    logging_steps=1,\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d6992f2-e8b5-4d30-b20f-783220435f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= threshold)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd1e1d8-bbc4-41f3-aa08-b960f0c06932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0]['labels'].type() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97fed2e9-2673-40b1-aa16-a94ea1929adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  7981, 10663,  1996,  3160,  2000,  4797,  9587, 29068,  3686,\n",
       "         7981,  5928,  1029,   102,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d0dcdb-5d44-4570-8581-395a27a074a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.6968, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[-0.1880,  0.2092,  0.0108,  ..., -0.0116, -0.0600, -0.1763]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1744265-09ae-439b-b339-d5e8c2d4712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='530' max='530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [530/530 00:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698400</td>\n",
       "      <td>0.698130</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.487680</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.698097</td>\n",
       "      <td>0.041243</td>\n",
       "      <td>0.487612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.699200</td>\n",
       "      <td>0.698075</td>\n",
       "      <td>0.041228</td>\n",
       "      <td>0.487527</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.699300</td>\n",
       "      <td>0.698061</td>\n",
       "      <td>0.041232</td>\n",
       "      <td>0.487553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.698057</td>\n",
       "      <td>0.041234</td>\n",
       "      <td>0.487564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=530, training_loss=0.6983522784035161, metrics={'train_runtime': 29.8038, 'train_samples_per_second': 141.425, 'train_steps_per_second': 17.783, 'total_flos': 1948037310720.0, 'train_loss': 0.6983522784035161, 'epoch': 5.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training \n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c65d7-3256-47ac-aba8-0e2dc0ba57a0",
   "metadata": {},
   "source": [
    "**Evaluating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d8c5ffa-88dd-423e-9d00-14d227af28c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6981296539306641,\n",
       " 'eval_f1': 0.041255046817283744,\n",
       " 'eval_roc_auc': 0.48767955642333494,\n",
       " 'eval_accuracy': 0.0,\n",
       " 'eval_runtime': 0.2274,\n",
       " 'eval_samples_per_second': 527.693,\n",
       " 'eval_steps_per_second': 65.962,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fdc8618-04d6-47c1-b2f7-6da5a95e3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1461, 843)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels), len(data['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e83c1-207c-48a2-bce6-8e01ffa99270",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f88a557-b714-4ea9-a64c-b4310399010c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14OS9eQKgfv63ZY7d5k4T8</td>\n",
       "      <td>[70948, 70949, 70950, 70951, 70952, 70953, 709...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14ambh1obhw7TYMQE8lcC1</td>\n",
       "      <td>[9637, 9638, 9639, 9641, 9642, 9637, 9638, 963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15kxeWhEKDnaQToOCK9BR2</td>\n",
       "      <td>[68053, 68174, 8432, 68188, 68177, 68096, 8632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15sKzdWMaXB8f0Mx9Aomk1</td>\n",
       "      <td>[190218, 190219, 265063, 172024, 190201, 19020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18Ccvc8NMJT5xqLv9nAgTH</td>\n",
       "      <td>[9839, 9843, 9847, 9850, 9859, 9864, 9867, 987...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   taskId                                           aspectId\n",
       "0  14OS9eQKgfv63ZY7d5k4T8  [70948, 70949, 70950, 70951, 70952, 70953, 709...\n",
       "1  14ambh1obhw7TYMQE8lcC1  [9637, 9638, 9639, 9641, 9642, 9637, 9638, 963...\n",
       "2  15kxeWhEKDnaQToOCK9BR2  [68053, 68174, 8432, 68188, 68177, 68096, 8632...\n",
       "3  15sKzdWMaXB8f0Mx9Aomk1  [190218, 190219, 265063, 172024, 190201, 19020...\n",
       "4  18Ccvc8NMJT5xqLv9nAgTH  [9839, 9843, 9847, 9850, 9859, 9864, 9867, 987..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df.groupby('taskId')['aspectId'].apply(list).reset_index()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a323ae01-403d-4627-90d7-f2951a4f6c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a sentence in the past tense. Use the following words: Yesterday - I - tell - story - a'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['taskId'] == \"14OS9eQKgfv63ZY7d5k4T8\"]['description'][19494]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cea81d88-89e1-4bb6-a23c-b542076cf1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.loc[0]['aspectId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23545627-a4c8-4638-90e7-9c1df32e60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['106', '5792', '5793', '5893', '7987', '7989', '8316', '8512', '8768', '8774', '8775', '8846', '8849', '8945', '9092', '9105', '9156', '9245', '9248', '9285', '9578', '9628', '9635', '9638', '9647', '9654', '9672', '9680', '9843', '9871', '9941', '9943', '9944', '9945', '9984', '9992', '10085', '10145', '10313', '10316', '10331', '10560', '10767', '10768', '10772', '11048', '11093', '11399', '11401', '11410', '11555', '11562', '11564', '11565', '11664', '11665', '11680', '11691', '11703', '11710', '11859', '11866', '12194', '12197', '12201', '12212', '12215', '12216', '12366', '12368', '12576', '12629', '12640', '12642', '12714', '12731', '12739', '12745', '12756', '12764', '12766', '12774', '12778', '12779', '12986', '13078', '13089', '13423', '13924', '13968', '13993', '14019', '14024', '14077', '14155', '16077', '16149', '27901', '27937', '27969', '28035', '60818', '60824', '60864', '60876', '60891', '60894', '60909', '61027', '61090', '62357', '68053', '68096', '68174', '68177', '68178', '68183', '68184', '68186', '68188', '68190', '68193', '70949', '70950', '70953', '70967', '70968', '70986', '70987', '70999', '71005', '71013', '71131', '71137', '71145', '71156', '80412', '80417', '80422', '80429', '80432', '80438', '80445', '91975', '92127', '92257', '100470', '171961', '171987', '172000', '172021', '172233', '172251', '172268', '172269', '172271', '172272', '172277', '172283', '172288', '172289', '176122', '181778', '181779', '181783', '181786', '181792', '181796', '181799', '181800', '181804', '181826', '190208', '190211', '190222', '190236', '190245', '190246', '190249', '190252', '190283', '190285', '224034', '244810', '244811', '244817', '246068', '246385', '246396', '246753', '247310', '247454', '265160', '265175', '265176', '265268', '265273', '265323', '265326', '265327', '272658', '272776', '272781', '272789', '272790', '272831', '272888']\n"
     ]
    }
   ],
   "source": [
    "text = \"Write a sentence in the past tense. Use the following words: Yesterday - I - tell - story - a\"\n",
    "\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "\n",
    "outputs = trainer.model(**encoding)\n",
    "logits = outputs.logits\n",
    "\n",
    "# apply sigmoid + threshold\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "probs = sigmoid(logits.squeeze().cpu())\n",
    "predictions = np.zeros(probs.shape)\n",
    "predictions[np.where(probs >= 0.55)] = 1\n",
    "# turn predicted id's into actual label names\n",
    "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "81de44c1-4103-4def-b4b1-61d3e49e83b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cde50e-9b05-4146-8743-216b857e3ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb_venv",
   "language": "python",
   "name": "tb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
