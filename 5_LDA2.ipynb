{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e7333f0-d1cb-4b93-8355-d13cc0d81c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011ab732-562f-4881-a700-705775485fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(data, min_len=3):\n",
    "    # Create a Dictionary: a mapping between words and their integer IDs\n",
    "    id2word = corpora.Dictionary(data)\n",
    "    \n",
    "    # Remove tokens of 1 or 2 letters\n",
    "    del_ids = [k for k,v in id2word.items() if len(v)<min_len]\n",
    "    id2word.filter_tokens(bad_ids=del_ids)\n",
    "    \n",
    "    # Create a corpus: a list of documents represented as a BoW\n",
    "    corpus = [id2word.doc2bow(text) for text in data]\n",
    "    \n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f194840a-ac33-455d-b17e-cb6b42dfc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(corpus, id2word, num_topics=3, passes=10, decay=0.5, iterations=50):\n",
    "    coh_scores = []\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus, \n",
    "        id2word=id2word, \n",
    "        num_topics=num_topics, \n",
    "        distributed=False,\n",
    "        passes=passes, \n",
    "        update_every=1,\n",
    "        alpha='auto', \n",
    "        eta=None, \n",
    "        decay=decay,\n",
    "        eval_every=5,\n",
    "        iterations=iterations, \n",
    "        per_word_topics=True)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=data, \n",
    "        dictionary=id2word, \n",
    "        coherence='c_v')\n",
    "        \n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(f\"topics={num_topics}, passes={passes}: {coherence_lda}\")\n",
    "\n",
    "    return lda_model, coherence_lda\n",
    "\n",
    "def plot_coh_score(coh_scores, x_range, title, language, save=True): \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(x_range, coh_scores, marker='o', linestyle='--')\n",
    "    ax.title.set_text(title)\n",
    "    ax.set_ylabel(\"Coherence score\")\n",
    "    ax.set_xlabel('Number of topics')\n",
    "    ax.grid(True)\n",
    "    if save:\n",
    "        ax.get_figure().savefig(\"figures/LDA_coh_\"+language, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "497e860c-06f9-47d0-a181-a2412d6d277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(corpus, id2word, title, language, plot=False, save_plot=False):\n",
    "    coh_scores = []\n",
    "    decay = 0.8 \n",
    "    iterations = 100\n",
    "    for num_topics, passes in product(range(2, 6), range(40, 120, 20)):\n",
    "        lda_model, coherence_lda = get_model(corpus, \n",
    "                                             id2word, \n",
    "                                             num_topics=num_topics, \n",
    "                                             passes=passes, \n",
    "                                             decay=decay, \n",
    "                                             iterations=iterations)\n",
    "        coh_scores.append(coherence_lda)\n",
    "        if coherence_lda == max(coh_scores):\n",
    "            best_model = lda_model\n",
    "\n",
    "    if plot:\n",
    "        plot_coh_score(coh_scores, title, language, save_plot)\n",
    "\n",
    "    return best_model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bda4a3-41b8-4c94-9137-731417d930e8",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770fde0-3069-45c7-b93f-8814cded92a6",
   "metadata": {},
   "source": [
    "**English tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d94a2c4a-abf0-4334-9e5a-bff341e34342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of df: 1129\n"
     ]
    }
   ],
   "source": [
    "folder = \"gen_files/EN/\"\n",
    "df = pd.read_csv(f\"{folder}preprocessed/open_tasks_EN.csv\")\n",
    "print(f\"Size of df: {len(df)}\")\n",
    "df_taskaspects = pd.read_csv(f\"{folder}taskAspects_EN.csv\")\n",
    "\n",
    "# Keeping only the tasks that have one or more aspects of type CONCEPT\n",
    "df = pd.merge(df, df_taskaspects, on=\"taskId\", how=\"inner\") \n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebdd2657-b804-407d-9eb3-a6c1aeb3d9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951, 951)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_taskaspects.taskId.unique()), len(df.taskId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae29077-ded6-4ddc-8303-bb4fd8a983a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df[[\"taskId\", \"description\", \"topic_id\"]].drop_duplicates(\"taskId\")\n",
    "_df = _df.dropna(subset=[\"description\"]).reset_index()\n",
    "data = _df[\"description\"].str.split().to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061f90c8-4400-4993-a7af-dfba9df7344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics=2, passes=40: 0.4166171331593141\n",
      "topics=2, passes=60: 0.4325940627406105\n",
      "topics=2, passes=80: 0.4123196871104018\n",
      "topics=2, passes=100: 0.41661713315931403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m id2word, corpus \u001b[38;5;241m=\u001b[39m get_corpus(data)\n\u001b[0;32m----> 2\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m get_best_model(corpus\u001b[38;5;241m=\u001b[39mcorpus, \n\u001b[1;32m      3\u001b[0m                            id2word\u001b[38;5;241m=\u001b[39mid2word, \n\u001b[1;32m      4\u001b[0m                            title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                            language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m, in \u001b[0;36mget_best_model\u001b[0;34m(corpus, id2word, title, language, plot, save_plot)\u001b[0m\n\u001b[1;32m      4\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_topics, passes \u001b[38;5;129;01min\u001b[39;00m product(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m6\u001b[39m), \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m120\u001b[39m, \u001b[38;5;241m20\u001b[39m)):\n\u001b[0;32m----> 6\u001b[0m     lda_model, coherence_lda \u001b[38;5;241m=\u001b[39m get_model(corpus, \n\u001b[1;32m      7\u001b[0m                                          id2word, \n\u001b[1;32m      8\u001b[0m                                          num_topics\u001b[38;5;241m=\u001b[39mnum_topics, \n\u001b[1;32m      9\u001b[0m                                          passes\u001b[38;5;241m=\u001b[39mpasses, \n\u001b[1;32m     10\u001b[0m                                          decay\u001b[38;5;241m=\u001b[39mdecay, \n\u001b[1;32m     11\u001b[0m                                          iterations\u001b[38;5;241m=\u001b[39miterations)\n\u001b[1;32m     12\u001b[0m     coh_scores\u001b[38;5;241m.\u001b[39mappend(coherence_lda)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m coherence_lda \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mmax\u001b[39m(coh_scores):\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(corpus, id2word, num_topics, passes, decay, iterations)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(corpus, id2word, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      2\u001b[0m     coh_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     lda_model \u001b[38;5;241m=\u001b[39m LdaModel(\n\u001b[1;32m      4\u001b[0m         corpus\u001b[38;5;241m=\u001b[39mcorpus, \n\u001b[1;32m      5\u001b[0m         id2word\u001b[38;5;241m=\u001b[39mid2word, \n\u001b[1;32m      6\u001b[0m         num_topics\u001b[38;5;241m=\u001b[39mnum_topics, \n\u001b[1;32m      7\u001b[0m         distributed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m         passes\u001b[38;5;241m=\u001b[39mpasses, \n\u001b[1;32m      9\u001b[0m         update_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     10\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m         eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m     12\u001b[0m         decay\u001b[38;5;241m=\u001b[39mdecay,\n\u001b[1;32m     13\u001b[0m         eval_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     14\u001b[0m         iterations\u001b[38;5;241m=\u001b[39miterations, \n\u001b[1;32m     15\u001b[0m         per_word_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(\n\u001b[1;32m     18\u001b[0m         model\u001b[38;5;241m=\u001b[39mlda_model, \n\u001b[1;32m     19\u001b[0m         texts\u001b[38;5;241m=\u001b[39mdata, \n\u001b[1;32m     20\u001b[0m         dictionary\u001b[38;5;241m=\u001b[39mid2word, \n\u001b[1;32m     21\u001b[0m         coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     coherence_lda \u001b[38;5;241m=\u001b[39m coherence_model_lda\u001b[38;5;241m.\u001b[39mget_coherence()\n",
      "File \u001b[0;32m~/anaconda3/envs/tb_venv/lib/python3.11/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(corpus, chunks_as_numpy\u001b[38;5;241m=\u001b[39muse_numpy)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tb_venv/lib/python3.11/site-packages/gensim/models/ldamodel.py:991\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    988\u001b[0m reallen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)  \u001b[38;5;66;03m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_every \u001b[38;5;129;01mand\u001b[39;00m ((reallen \u001b[38;5;241m==\u001b[39m lencorpus) \u001b[38;5;129;01mor\u001b[39;00m ((chunk_no \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (eval_every \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumworkers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_perplexity(chunk, total_docs\u001b[38;5;241m=\u001b[39mlencorpus)\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher:\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;66;03m# add the chunk to dispatcher's job queue, so workers can munch on it\u001b[39;00m\n\u001b[1;32m    995\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, dispatching documents up to #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    997\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[1;32m    998\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tb_venv/lib/python3.11/site-packages/gensim/models/ldamodel.py:847\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    845\u001b[0m corpus_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cnt \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m chunk \u001b[38;5;28;01mfor\u001b[39;00m _, cnt \u001b[38;5;129;01min\u001b[39;00m document)\n\u001b[1;32m    846\u001b[0m subsample_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m total_docs \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m--> 847\u001b[0m perwordbound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound(chunk, subsample_ratio\u001b[38;5;241m=\u001b[39msubsample_ratio) \u001b[38;5;241m/\u001b[39m (subsample_ratio \u001b[38;5;241m*\u001b[39m corpus_words)\n\u001b[1;32m    848\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m per-word bound, \u001b[39m\u001b[38;5;132;01m%.1f\u001b[39;00m\u001b[38;5;124m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m documents with \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m words\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     perwordbound, np\u001b[38;5;241m.\u001b[39mexp2(\u001b[38;5;241m-\u001b[39mperwordbound), \u001b[38;5;28mlen\u001b[39m(chunk), corpus_words\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[0;32m~/anaconda3/envs/tb_venv/lib/python3.11/site-packages/gensim/models/ldamodel.py:1122\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Elogthetad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# E[log p(doc | theta, beta)]\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cnt \u001b[38;5;241m*\u001b[39m logsumexp(Elogthetad \u001b[38;5;241m+\u001b[39m Elogbeta[:, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mid\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, cnt \u001b[38;5;129;01min\u001b[39;00m doc)\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m-\u001b[39m gammad) \u001b[38;5;241m*\u001b[39m Elogthetad)\n",
      "File \u001b[0;32m~/anaconda3/envs/tb_venv/lib/python3.11/site-packages/gensim/models/ldamodel.py:1122\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Elogthetad\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# E[log p(doc | theta, beta)]\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cnt \u001b[38;5;241m*\u001b[39m logsumexp(Elogthetad \u001b[38;5;241m+\u001b[39m Elogbeta[:, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mid\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, cnt \u001b[38;5;129;01min\u001b[39;00m doc)\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m-\u001b[39m gammad) \u001b[38;5;241m*\u001b[39m Elogthetad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id2word, corpus = get_corpus(data)\n",
    "lda_model = get_best_model(corpus=corpus, \n",
    "                           id2word=id2word, \n",
    "                           title=\"\", \n",
    "                           language=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8e47d-fa20-4f00-bd21-91d4d41a663d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb_venv",
   "language": "python",
   "name": "tb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
