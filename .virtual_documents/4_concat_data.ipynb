


import pandas as pd 


filenames = [
    "taskAspects_DE",
    "taskAspects_BT_DE", 
    "taskAspects_RD_DE", 
    "taskAspects_RI_DE", 
    "taskAspects_RS_DE", 
    "taskAspects_SR_DE", 
]
df = pd.DataFrame() 

for filename in filenames:
    _df = pd.read_csv("data/"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_taskAspects_DE.csv", index_label=False)


filenames = [
    "taskAspects_EN",
    "taskAspects_BT_EN", 
    "taskAspects_RD_EN", 
    "taskAspects_RI_EN", 
    "taskAspects_RS_EN", 
    "taskAspects_SR_EN", 
]
df = pd.DataFrame() 

for filename in filenames:
    _df = pd.read_csv("data/"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_taskAspects_EN.csv", index_label=False)


filenames = [
    "open_tasks_DE",
    "augmented_BT_DE", 
    "augmented_RD_DE", 
    "augmented_RI_DE", 
    "augmented_RS_DE", 
    "augmented_SR_DE", 
]
df = pd.DataFrame() 

for filename in filenames:
    _df = pd.read_csv("data/"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_augmented_tasks_DE.csv", index_label=False)


df = pd.DataFrame() 
for filename in filenames:
    _df = pd.read_csv("data/preprocessed_"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_preprocessed_tasks_DE.csv", index_label=False)


filenames = [
    "open_tasks_EN",
    "augmented_BT_EN", 
    "augmented_RD_EN", 
    "augmented_RI_EN", 
    "augmented_RS_EN", 
    "augmented_SR_EN", 
] 
df = pd.DataFrame() 
for filename in filenames: 
    _df = pd.read_csv("data/"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_augmented_tasks_EN.csv", index_label=False)

df = pd.DataFrame() 
for filename in filenames: 
    _df = pd.read_csv("data/preprocessed_"+filename+".csv")
    df = pd.concat([df, _df],  ignore_index=True) 
df.to_csv("data/all_preprocessed_tasks_EN.csv", index_label=False)





import gensim.corpora as corpora
from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt

def get_word_counts(texts): 
    # create the vocabulary 
    vectorizer = CountVectorizer() 
    # Fit and transform the documents
    X = vectorizer.fit_transform(texts)
    # Get the occurrences of each word
    word_occurrences = X.toarray().sum(axis=0)
    # Map the indices to words in the vocabulary
    word_counts = {word: word_occurrences[idx] for word, idx in vectorizer.vocabulary_.items()}
    return word_counts

def plot_word_counts(word_counts):
    # Sort the word counts by frequency
    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)
    
    # Extract words and their corresponding counts
    words, counts = zip(*sorted_word_counts)
    
    # Plot the word counts
    plt.figure(figsize=(20, 12))
    plt.bar(range(len(words)), counts, log=True)
    plt.xticks(rotation=90)
    plt.xlabel('Words')
    plt.ylabel('Occurrences')
    plt.title('Word Occurrences')
    plt.show()

    return sorted_word_counts


df = pd.read_csv("data/all_augmented_tasks_DE.csv")
df.dropna(subset=["description"], inplace=True)
texts = df["description"].to_list() 

sorted_word_counts = plot_word_counts(get_word_counts(texts))


# sorted_word_counts[:20], sorted_word_counts[-10:]


df = pd.read_csv("data/all_preprocessed_tasks_DE.csv")
df.dropna(subset=["description"], inplace=True)
texts = df["description"].to_list() 

sorted_word_counts = plot_word_counts(get_word_counts(texts))





df = pd.read_csv("data/all_augmented_tasks_EN.csv")
df.dropna(subset=["description"], inplace=True)
texts = df["description"].to_list() 

sorted_word_counts = plot_word_counts(get_word_counts(texts))


sorted_word_counts[:10], sorted_word_counts[-10:]


df = pd.read_csv("data/all_preprocessed_tasks_EN.csv")
df.dropna(subset=["description"], inplace=True)
texts = df["description"].to_list() 

sorted_word_counts = plot_word_counts(get_word_counts(texts))


sorted_word_counts[:50], sorted_word_counts[-10:]



