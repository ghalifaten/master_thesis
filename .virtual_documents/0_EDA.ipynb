





import warnings
warnings.filterwarnings("ignore")


import mysql.connector
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import json
from bs4 import BeautifulSoup


sns.set_theme(style='white', 
              rc={'figure.figsize':(12,6)})
color_blind_colors = [
    "#00429d",  # Dark blue
    "#009c79",  # Dark green
    "#ff420e",  # Orange
    "#365e96",  # Blue
    "#ffbb00",  # Yellow
    "#a200ff",  # Purple
    "#01b1d2",  # Cyan
    "#00558c",  # Dark blue
    "#9e0638",  # Red
    "#00a03e",  # Green
    "#ffcd00",  # Yellow
    "#7a6fca",  # Blue
    "#3f3f3f",  # Gray
    "#af280e",  # Red
    "#c3d825",  # Green-yellow
    "#3a4276",  # Blue
    "#1f8a70",  # Green
    "#ff6800",  # Orange
    "#5b5a5a",  # Gray
    "#c49867",  # Brown
    "#827a04",  # Olive
    "#83a4d4",  # Light blue
    "#44a1c2",  # Blue
    "#c4b97f",  # Olive
    "#8a88a3",  # Purple
    "#da8137",  # Orange
    "#dc5f3b",  # Red-orange
    "#a67e2d",  # Yellow-brown
    "#b7aa89",  # Gray
    "#647d6e",  # Green
    "#6aabb1",  # Cyan
    "#a07f29",  # Yellow-brown
    "#d7a844",  # Yellow-orange
    "#6e764d"   # Olive
]


cnx = mysql.connector.connect(user='root', password='taskbase',
                              host='127.0.0.1', port='3309', database='lernnavi')





query = "SELECT * FROM TaskTypes"
df_types = pd.read_sql(query, cnx)
df_types.rename(columns={'id':'typeId', 'name':'type'}, inplace=True)
df_types.head()


query = "SELECT * FROM Tasks"
df_tasks = pd.read_sql(query, cnx)
df_tasks = pd.merge(df_tasks, df_types, how="inner", on='typeId')
df_tasks.head()


query = "SELECT * FROM LatestTaskVersions"
df = pd.read_sql(query, cnx)
df_latest_task_versions = pd.merge(df_tasks, df, how="inner", on=["version", "taskId"])
L = len(df_latest_task_versions)
df_latest_task_versions.head() 


types_count = df_latest_task_versions[["type", "taskId"]].groupby("type").count().rename(columns={"taskId":"count"}).reset_index()

colors = ['tab:blue' for x in types_count.type]
colors[-3] = 'red'

ax = sns.barplot(data=types_count,
                 x='type',
                 y="count",
                 order=types_count.sort_values('count').type, palette=colors)

plt.xticks(rotation=90)
ax.get_xticklabels()[-3].set_color("red")
title = plt.title("Types of tasks sorted by count")
ax.get_figure().savefig("figures/types_count_sorted.png", bbox_inches="tight") 



open_count = types_count[types_count['type'] == "OPEN"].reset_index().loc[0,"count"]
print("Percentage of OPEN tasks: {:.2f}%".format(open_count / types_count['count'].sum() * 100))





df_latest_task_versions.head()


# Get titles and descriptions of last versions of tasks 
df = df_latest_task_versions[["title", "content"]]
df = pd.concat([df, df["content"].apply(json.loads).apply(pd.Series)], axis=1)
columns_to_keep = ["id", "type", "description", "solution", "sampleSolutions", "language", "tenant", "topic", "context"]
df_content = df[columns_to_keep]
df_content.head()


tenants = df_content["tenant"].apply(pd.Series)[["name"]]
tenants.rename(columns={"name":"tenant_name"}, inplace=True)
df_content = pd.concat([df_content, tenants], axis=1)


df_content.head()


df_content["type"] = df_content["type"].apply(lambda t: t if t=="OPEN" else "OTHER")


# Distribution of tasks' types among tenants 
ax = sns.histplot(data=df_content,
                  x="tenant_name",
                  hue="type",
                  multiple="stack", 
                  palette=["tab:blue", "red"],
                 )
ax.set_yscale("log")
ax.set_xticklabels('')
ax.set_xlabel("Tenants")
ax.get_figure().savefig("figures/types_tenants.png", bbox_inches="tight") 
plt.show()





df_open = df_content[df_content["type"] == "OPEN"]


df_open["language"].unique()


# How many tasks with language specified ? 
L = len(df_open)
print("{:.2f}%".format(len(df_open["language"].dropna()) / L * 100))


l = len(df_open[df_open["language"].isna()])
nan_perc = l/L
print("Nan:  {:.2f}%".format(nan_perc*100))


df_open["language"] = df_open["language"].apply(lambda l: "NaN" if str(l) == "nan" else l)
df_open["language"] = df_open["language"].apply(lambda l: "DE" if l == "DE_DE" else l)

ax = sns.histplot(data=df_open,
                  x="language",
                  shrink=0.8)
# title = plt.title("Distribution of languages of the OPEN tasks.")
ax.get_figure().savefig("figures/languages_distribution.png", bbox_inches="tight") 


# Portion of DE/EN tasks
print("{:.2f}%".format(len(df_open[df_open["language"].isin(["DE", "EN"])]) / L * 100))


# How many tasks with solution ?
print("{:.2f}%".format(len(df_open["solution"].dropna()) / L * 100))


# How many tasks with topic specified ? 
print("{:.2f}%".format(len(df_open["topic"].dropna()) / L * 100))


# How many tasks with tenant specified ? 
print("{:.2f}%".format(len(df_open["tenant"].dropna()) / L * 100))





df_open.head()


# Lengths of descriptions => need pre-processing ? cleaning html tags 
clean_descriptions = df_open[["id", "description", "language", "context", "tenant_name"]]
clean_descriptions.rename(columns={"id":"taskId"}, inplace=True) 
clean_descriptions["description"] = clean_descriptions["description"].apply(lambda str: BeautifulSoup(str, 'html.parser').get_text().strip())
clean_descriptions = pd.DataFrame(clean_descriptions.reset_index(drop=True))
clean_descriptions["word_count"] = clean_descriptions["description"].apply(lambda s: len(s.split()))
clean_descriptions.sort_values(by="word_count", inplace=True)
L = len(clean_descriptions)


clean_descriptions.head()


clean_descriptions[~clean_descriptions["language"].isin(["FR", "IT"])].to_csv("data/EDA_result.csv", index_label=False)


df_both = clean_descriptions[clean_descriptions["language"].isin(["DE", "EN"])]


df_both = df_both.sort_values(by="language")


fig, ax = plt.subplots(1, 1, figsize=(12, 5))

sns.histplot(data=df_both, x="word_count", hue="language", kde=True, stat="density", palette=["tab:blue", "tab:orange"])
ax.set_xscale("log")

fig.savefig("figures/description_lengths_1", bbox_inches="tight") 


# How many empty descriptions ?
empty = df_both[df_both["word_count"] == 0]
print("Empty descriptions: {:.2f}%".format(len(empty) / L * 100))

# How many short descriptions ?
tail = df_both[df_both["word_count"] < 5]
print("Descriptions of < 5 words: {:.2f}%".format(len(tail) / L * 100))

# How many short descriptions ?
tail = df_both[df_both["word_count"] < 10]
print("Descriptions of < 10 words: {:.2f}%".format(len(tail) / L * 100))

# How heavy is the tail ?
tail = df_both[df_both["word_count"] > 100]
print("Descriptions of > 100 words: {:.2f}%".format(len(tail) / L * 100))

# How heavy is the tail ?
tail = df_both[df_both["word_count"] > 200]
print("Descrishaggy & daddyptions of > 200 words: {:.2f}%".format(len(tail) / L * 100))








# All Aspects
query = "SELECT * FROM Aspects"
df_aspects = pd.read_sql(query, cnx)
df_aspects.rename(columns={"id":"aspectId"}, inplace=True)
df_aspects = df_aspects[["aspectId", "description", "type", "groupId", "categoryId"]]
# df_aspects.to_csv("data/aspects.csv", index_label=False)
df_aspects.head()


L = len(df_aspects)


df_aspects.type.unique(), len(df_aspects[df_aspects["type"] == "CONCEPT"]), len(df_aspects[df_aspects["type"] == "MISCONCEPTION"])


len(df_aspects.groupId.unique())


len(df_aspects.categoryId.unique())


df_aspects = df_aspects[df_aspects["type"] == "CONCEPT"]
L = len(df_aspects)


L 


# Portion of aspects with specified groupId
len(df_aspects.dropna(subset=["groupId"])) / L * 100


# Portion of aspects with specified categoryId
len(df_aspects.dropna(subset=["categoryId"])) / L * 100



