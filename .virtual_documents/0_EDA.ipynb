


import warnings
warnings.filterwarnings("ignore")


import mysql.connector
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import json
from bs4 import BeautifulSoup


sns.set_theme(style='white', 
              rc={'figure.figsize':(15,8)})
color_blind_colors = [
    "#00429d",  # Dark blue
    "#009c79",  # Dark green
    "#ff420e",  # Orange
    "#365e96",  # Blue
    "#ffbb00",  # Yellow
    "#a200ff",  # Purple
    "#01b1d2",  # Cyan
    "#00558c",  # Dark blue
    "#9e0638",  # Red
    "#00a03e",  # Green
    "#ffcd00",  # Yellow
    "#7a6fca",  # Blue
    "#3f3f3f",  # Gray
    "#af280e",  # Red
    "#c3d825",  # Green-yellow
    "#3a4276",  # Blue
    "#1f8a70",  # Green
    "#ff6800",  # Orange
    "#5b5a5a",  # Gray
    "#c49867",  # Brown
    "#827a04",  # Olive
    "#83a4d4",  # Light blue
    "#44a1c2",  # Blue
    "#c4b97f",  # Olive
    "#8a88a3",  # Purple
    "#da8137",  # Orange
    "#dc5f3b",  # Red-orange
    "#a67e2d",  # Yellow-brown
    "#b7aa89",  # Gray
    "#647d6e",  # Green
    "#6aabb1",  # Cyan
    "#a07f29",  # Yellow-brown
    "#d7a844",  # Yellow-orange
    "#6e764d"   # Olive
]


cnx = mysql.connector.connect(user='root', password='taskbase',
                              host='127.0.0.1', port='3309', database='lernnavi')





query = "SELECT * FROM DocumentTypes"
df_types = pd.read_sql(query, cnx)
df_types.rename(columns={'id':'typeId', 'name':'type'}, inplace=True)
df_types.head()


query = "SELECT * FROM Documents"
df_tasks = pd.read_sql(query, cnx)
df_tasks = pd.merge(df_tasks, df_types, how="inner", on='typeId')
df_tasks.head()


query = "SELECT * FROM LatestDocumentVersions"
df = pd.read_sql(query, cnx)
df_latest_task_versions = pd.merge(df_tasks, df, how="inner", on=["version", "documentId"])
L = len(df_latest_task_versions)
df_latest_task_versions.head() 





types_count = df_latest_task_versions[["type", "documentId"]].groupby("type").count().rename(columns={"documentId":"count"}).reset_index()

ax = sns.barplot(data=types_count,
                 x='type',
                 y="count",
                 order=types_count.sort_values('count').type)

plt.xticks(rotation=90)
title = plt.title("Types of tasks sorted by count")


lowest_counts = types_count.sort_values(by="count", ascending=False)[16:] # ID 29 to 27
# lowest_counts = types_count[18:] # ID 29 to 20
p = lowest_counts['count'].sum() / types_count['count'].sum() * 100
print("The types of lowest counts (ID 29 to ID 27) correspond to {p:.2f}% of the number of tasks.".format(p=p))





# Get titles and descriptions of last versions of tasks 
df = df_latest_task_versions[["title", "content"]]
df = pd.concat([df, df["content"].apply(json.loads).apply(pd.Series)], axis=1)
columns_to_keep = ["type", "clozeText", "description", "documentType", "clozeElements", "textWithMistakes", "solution", "language", "tenant", "topic"]
df_content = df[columns_to_keep]
# df_content.head()


# How many documents with solution ?
print("{:.2f}%".format(len(df_content["solution"].dropna()) / L * 100))


# How many documents with language specified ? 
print("{:.2f}%".format(len(df_content["language"].dropna()) / L * 100))


# How many documents with topic specified ? 
print("{:.2f}%".format(len(df_content["topic"].dropna()) / L * 100))


# How many documents with tenant specified ? 
print("{:.2f}%".format(len(df_content["tenant"].dropna()) / L * 100))


# Distribution of documents among tenants
tenants = df_content["tenant"].apply(pd.Series)
tenants_count = tenants.groupby(by="name").count()[["id"]].rename(columns={"id":"count"}).reset_index()

sns.set_theme(style='white', 
              font_scale=0.7, 
              rc={'figure.figsize':(15,8)})

ax = sns.barplot(data=tenants_count,
                 x="name",
                 y="count",
                 order=tenants_count.sort_values('count').name,
                 )
plt.xticks(rotation=90)
title = plt.title("Number of documents by tenant. All types combined.")


df_content = pd.concat([df_content, tenants], axis=1)


# Distribution of documents' types among tenants 
sns.set_theme(style='white', 
              font_scale=0.7, 
              rc={'figure.figsize':(15,8)})

ax = sns.histplot(data=df_content,
                  x="name",
                  hue="type",
                  multiple="stack", 
                  palette=color_blind_colors,
                 )
ax.set_yscale("log")
plt.xticks(rotation=90)
title = plt.title("Number of documents by tenant. All types combined.")


# Tenants with most CLOZE and OPEN tasks
task_types = ["OPEN", "CLOZE_TEXT_INPUT"]
df_cloze_open = df_content[df_content["type"].isin(task_types)]

ax = sns.histplot(data=df_cloze_open,
                  x="name",
                  hue="type",
                  multiple="stack"
                 )
# ax.set_yscale("log")
x = plt.xticks(rotation=90)
title = plt.title("Number by tenant of documents of types 'OPEN' and 'CLOZE_TEXT_INPUT'.")


# How many CLOZE OPEN with language specified ?
print("{:.2f}%".format(len(df_cloze_open["language"].dropna())/ len(df_cloze_open) * 100))


# What is the portion of English and German cloze/open documents ? NaN included in total
print("{:.2f}%".format(len(df_cloze_open[df_cloze_open["language"].isin(["DE", "EN"])]) / len(df_cloze_open) * 100))


ax = sns.histplot(data=df_cloze_open,
                  x="language",
                  shrink=0.8)
title = plt.title("Distribution of languages of the OPEN and CLOZE_TEXT_INPUT tasks.")





df_corn_ekv = df_content[df_content["name"].isin(["Cornelsen DE", "EKV_Physik"])]
sns.set_theme(style='white', 
              font_scale=1, 
              rc={'figure.figsize':(8,6)})

ax = sns.histplot(data=df_corn_ekv,
                  x="name",
                  hue="type",
                  multiple="stack",
                  shrink=0.5
                 )





# Lengths of descriptions => need pre-processing ? cleaning html tags 
clean_descriptions = df_cloze_open[["description", "language"]]
clean_descriptions["description"] = clean_descriptions["description"].apply(lambda str: BeautifulSoup(str, 'html.parser').get_text().strip())
clean_descriptions = pd.DataFrame(clean_descriptions.reset_index(drop=True))
clean_descriptions["word_count"] = clean_descriptions["description"].apply(lambda s: len(s.split()))
clean_descriptions.sort_values(by="word_count", inplace=True)
L = len(clean_descriptions)


df_cloze_open_EN = df_cloze_open[df_cloze_open["language"] == "EN"]
df_cloze_open_DE = df_cloze_open[df_cloze_open["language"] == "DE"]


sns.set_theme(style='white', 
              rc={'figure.figsize':(15,8)})

sns.histplot(data=clean_descriptions,
                  x="word_count"
                 )
title = plt.title("Distribution of description text by length (in words). All languages combined.")


sns.set_theme(style='white', 
              rc={'figure.figsize':(15,8)})

ax = sns.histplot(data=clean_descriptions,
                  x="word_count"
                 )
ax.set_yscale("log")
title = plt.title("Distribution of description text by length (in words). All languages combined.")


# How many empty descriptions ?
empty = clean_descriptions[clean_descriptions["word_count"] == 0]
print("{:.2f}%".format(len(empty) / L * 100))


# How heavy is the tail ?
tail = clean_descriptions[clean_descriptions["word_count"] > 200]
print("{:.2f}%".format(len(tail) / L * 100))


# How heavy is the tail ?
tail = clean_descriptions[clean_descriptions["word_count"] > 100]
print("{:.2f}%".format(len(tail) / L * 100))


clean_descriptions.head()


sns.set_theme(style='white', 
              rc={'figure.figsize':(15,8)})

ax = sns.histplot(data=clean_descriptions[clean_descriptions["language"] == "EN"],
                  x="word_count"
                 )
# ax.set_yscale("log")
title = plt.title("Distribution of ENGLISH description text by length (in words).")


sns.set_theme(style='white', 
              rc={'figure.figsize':(15,8)})

ax = sns.histplot(data=clean_descriptions[clean_descriptions["language"] == "DE"],
                  x="word_count"
                 )
# ax.set_yscale("log")
title = plt.title("Distribution of GERMAN description text by length (in words).")





df_cloze_open_topics = df_cloze_open_EN["topic"].apply(pd.Series)


df_cloze_open_topics.dropna(subset=["name"]).name.unique()








pd.set_option('display.max_rows', 500)
query = "SELECT * FROM Tenants"
df = pd.read_sql(query, cnx)
df[df["lang"] == "DE"]


query = "SELECT * FROM Competences"
df_aspects = pd.read_sql(query, cnx)
# df_aspects.head()

df_aspects_cornelsen = df_aspects[df_aspects["tenantId"]==95]
df_aspects_ekvphysik = df_aspects[df_aspects["tenantId"]==140]
# df_aspects_cornelsen.head()
df_aspects_ekvphysik.head()


df_aspects["description"][6790]





query = "SELECT * FROM AspectConfigurations"
df_detectors = pd.read_sql(query, cnx)
df_detectors.head()






