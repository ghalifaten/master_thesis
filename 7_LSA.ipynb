{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5f17c4-1285-4aac-ba89-26602330daa8",
   "metadata": {},
   "source": [
    "This notebook explores and implements Latent Semantic Analysis. <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3c8fcde-f4c5-48ef-a4ed-498a060cdf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "685c647c-afba-4286-825b-5d5591517376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7fcf97f-ea20-4e94-bc10-9776ed7b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa(texts, num_topics=5):\n",
    "    # Step 1: Convert texts to TF-IDF matrix\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=1, stop_words=stop_words)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # Step 2: Apply Singular Value Decomposition (SVD)\n",
    "    svd = TruncatedSVD(n_components=num_topics)\n",
    "    latent_semantic_analysis = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    # Step 3: Normalize the output of SVD\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    latent_semantic_analysis = normalizer.fit_transform(latent_semantic_analysis)\n",
    "    \n",
    "    # Step 4: Print the topics and their most relevant terms\n",
    "    terms = tfidf_vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for i, topic in enumerate(svd.components_):\n",
    "        top_terms_idx = topic.argsort()[:-21:-1] # Top 50 terms\n",
    "        top_terms = [terms[idx] for idx in top_terms_idx]\n",
    "        topics.append(top_terms)\n",
    "    return tfidf_vectorizer, svd, normalizer, latent_semantic_analysis, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37b81f4e-d350-4507-8f4d-74943dc48408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(texts):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=1, stop_words=stop_words)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    return tfidf_vectorizer, tfidf_matrix\n",
    "\n",
    "def transform_text(text, tfidf_vectorizer, svd, normalizer):\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    text_lsa = svd.transform(text_tfidf)\n",
    "    text_lsa_normalized = normalizer.transform(text_lsa)\n",
    "    return text_lsa_normalized\n",
    "\n",
    "def assign_topic_to_text(text, topics_lsa_normalized):\n",
    "    # Transform test text to LSA space\n",
    "    text_lsa_normalized = transform_text(text, tfidf_vectorizer, svd, normalizer)\n",
    "\n",
    "    similarities = cosine_similarity(text_lsa_normalized, topics_lsa_normalized)\n",
    "    # print(similarities)\n",
    "    most_similar_topic_index = np.argmax(similarities)\n",
    "    return most_similar_topic_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673fb0cf-950d-454c-9fcb-95180164d89a",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ba93ec5-191b-4580-b255-787ae33c8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "df = pd.read_csv(\"gen_files/EN/preprocessed/trimmed_open_tasks.csv\")\n",
    "stop_words = stopwords.words('english')\n",
    "df = df.dropna(subset=[\"description\"]).reset_index(drop=True)\n",
    "data = df[\"description\"].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d00f03e4-24ea-4d11-bcc1-63bb9748bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize documents for Gensim\n",
    "tokenized_docs = [doc.split() for doc in data]\n",
    "# Create a Gensim dictionary and corpus\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0a8f2cf-1f49-4b9b-82ad-527dfbfd715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_scores = []\n",
    "for num_topics in range(2,11):\n",
    "    tfidf_vectorizer, svd, normalizer, lsa_output, topics = lsa(data, num_topics=num_topics)\n",
    "    # Convert top words per topic into the format required by CoherenceModel\n",
    "    cm_topics = [[dictionary.token2id[word] for word in topic] for topic in topics]\n",
    "    # Compute Coherence Score using the 'u_mass' coherence measure\n",
    "    coherence_model = CoherenceModel(topics=cm_topics, texts=tokenized_docs, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_score = coherence_model.get_coherence() # mean of coherence scores per topic\n",
    "    coh_scores.append(coherence_score)\n",
    "    if coherence_score == max(coh_scores):\n",
    "        best_n = num_topics\n",
    "        best_model = (tfidf_vectorizer, svd, normalizer, lsa_output, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d858c87-02fb-4927-a2f0-c53601ce759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68c236-cbbb-43d1-b389-c82284b61626",
   "metadata": {},
   "source": [
    "Assign topics to tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d84d914c-eabf-4d7a-89a9-7383a46d5b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tfidf_vectorizer, svd, normalizer, lsa_output, topics) = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "50c8772b-64ad-4332-a880-5e16d9edea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform topics to LSA space\n",
    "list_topics_normalized = []\n",
    "for topic in topics:\n",
    "    list_topics_normalized.append(transform_text(\" \".join(topic), tfidf_vectorizer, svd, normalizer)[0].tolist())\n",
    "    topics_lsa_normalized = np.array(list_topics_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ba981f8d-4910-4c96-b894-9981f753a638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a topic to each task of df \n",
    "\n",
    "df_task_topic = df[[\"taskId\",\"description\"]] \n",
    "df_task_topic[\"task_topic\"] = df_task_topic[\"description\"].apply(lambda text: assign_topic_to_text(text, topics_lsa_normalized))\n",
    "# df_task_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3414d8-d469-404b-8064-001278d487d3",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666468c-f65d-4d66-ab64-4f75dd38308c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd399aca-043a-47a8-beca-4ca63c9cd3d3",
   "metadata": {},
   "source": [
    "LSA on aspects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0bd2deb0-d770-47c1-9d69-b0e0e48628c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"gen_files/EN/preprocessed/concept_aspects.csv\")\n",
    "stop_words = stopwords.words('english')\n",
    "df = df.dropna(subset=[\"description\"]).reset_index(drop=True)\n",
    "data = df[\"description\"].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26b3a015-f59f-459f-8c03-b7c396505393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize documents for Gensim\n",
    "tokenized_docs = [doc.split() for doc in data]\n",
    "# Create a Gensim dictionary and corpus\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b89256b1-8994-4adf-b41f-d2b74ddb6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_scores = []\n",
    "for num_topics in range(2,11):\n",
    "    tfidf_vectorizer, svd, normalizer, lsa_output, topics = lsa(data, num_topics=num_topics)\n",
    "    # Convert top words per topic into the format required by CoherenceModel\n",
    "    cm_topics = [[dictionary.token2id[word] for word in topic] for topic in topics]\n",
    "    # Compute Coherence Score using the 'u_mass' coherence measure\n",
    "    coherence_model = CoherenceModel(topics=cm_topics, texts=tokenized_docs, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence_score = coherence_model.get_coherence() # mean of coherence scores per topic\n",
    "    coh_scores.append(coherence_score)\n",
    "    if coherence_score == max(coh_scores):\n",
    "        best_n = num_topics\n",
    "        best_model = (tfidf_vectorizer, svd, normalizer, lsa_output, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "402a427c-efe5-4a9e-870b-859786b383b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(tfidf_vectorizer, svd, normalizer, lsa_output, topics) = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9609062-5b6d-46ee-ba88-fc1e546f27cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics), best_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95e89621-d46a-4fed-bda4-ca9a43664f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform topics to LSA space\n",
    "list_topics_normalized = []\n",
    "for topic in topics:\n",
    "    list_topics_normalized.append(transform_text(\" \".join(topic), tfidf_vectorizer, svd, normalizer)[0].tolist())\n",
    "    topics_lsa_normalized = np.array(list_topics_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "326ad6a2-049f-43ae-b6d3-f1d2112bddf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectId</th>\n",
       "      <th>description</th>\n",
       "      <th>aspect_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9639</td>\n",
       "      <td>word right order</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9937</td>\n",
       "      <td>good answer orang utan strong social bond</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9633</td>\n",
       "      <td>subject verb congruent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11401</td>\n",
       "      <td>answer mention keyword look correctstat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9984</td>\n",
       "      <td>verb conjug expect ten expectedten</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aspectId                                description  aspect_topic\n",
       "0      9639                           word right order             0\n",
       "1      9937  good answer orang utan strong social bond             2\n",
       "2      9633                     subject verb congruent             3\n",
       "3     11401    answer mention keyword look correctstat             2\n",
       "4      9984         verb conjug expect ten expectedten             3"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a topic to each aspect of df \n",
    "\n",
    "df_aspect_topic = df[[\"aspectId\",\"description\"]] \n",
    "df_aspect_topic[\"aspect_topic\"] = df_aspect_topic[\"description\"].apply(lambda text: assign_topic_to_text(text, topics_lsa_normalized))\n",
    "df_aspect_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397600d-c560-4df7-b5e0-3aa121b35831",
   "metadata": {},
   "source": [
    "Mapping aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a5595ed-ba14-4c90-91b7-d8d81b2ca27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_aspects = pd.read_csv(\"gen_files/EN/taskAspects.csv\")\n",
    "# df_task_aspects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae80e9c0-0286-4d2c-b3ca-26a4c78ec303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspectId</th>\n",
       "      <th>description</th>\n",
       "      <th>task_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14ambh1obhw7TYMQE8lcC1</td>\n",
       "      <td>9639</td>\n",
       "      <td>write short text sentenc past simpl word usual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25RGLvb2p0G5zulfX9xQOj</td>\n",
       "      <td>9639</td>\n",
       "      <td>man woman write sentenc posit neg happen pictu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18Ccvc8NMJT5xqLv9nAgTH</td>\n",
       "      <td>9937</td>\n",
       "      <td>anim write sentenc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3Jr6T26XL13aKRh31JX0xi</td>\n",
       "      <td>9633</td>\n",
       "      <td>peopl pictur visit london write day london poi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3gbjpjewKN1aa5y4aN20Yw</td>\n",
       "      <td>11401</td>\n",
       "      <td>time mull wine gluhwein german vin chaud frenc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>16MreBTRQqA9TQI3zQU33G</td>\n",
       "      <td>124</td>\n",
       "      <td>battl waterloo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218</th>\n",
       "      <td>16MreBTRQqA9TQI3zQU33G</td>\n",
       "      <td>71160</td>\n",
       "      <td>battl waterloo</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>8gooLcJt0bz7yVHSaWd0MM</td>\n",
       "      <td>71121</td>\n",
       "      <td>read follow articl georg lunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11220</th>\n",
       "      <td>8gooLcJt0bz7yVHSaWd0MM</td>\n",
       "      <td>124</td>\n",
       "      <td>read follow articl georg lunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>8gooLcJt0bz7yVHSaWd0MM</td>\n",
       "      <td>71160</td>\n",
       "      <td>read follow articl georg lunch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       taskId  aspectId  \\\n",
       "0      14ambh1obhw7TYMQE8lcC1      9639   \n",
       "1      25RGLvb2p0G5zulfX9xQOj      9639   \n",
       "2      18Ccvc8NMJT5xqLv9nAgTH      9937   \n",
       "3      3Jr6T26XL13aKRh31JX0xi      9633   \n",
       "4      3gbjpjewKN1aa5y4aN20Yw     11401   \n",
       "...                       ...       ...   \n",
       "11217  16MreBTRQqA9TQI3zQU33G       124   \n",
       "11218  16MreBTRQqA9TQI3zQU33G     71160   \n",
       "11219  8gooLcJt0bz7yVHSaWd0MM     71121   \n",
       "11220  8gooLcJt0bz7yVHSaWd0MM       124   \n",
       "11221  8gooLcJt0bz7yVHSaWd0MM     71160   \n",
       "\n",
       "                                             description  task_topic  \n",
       "0      write short text sentenc past simpl word usual...           0  \n",
       "1      man woman write sentenc posit neg happen pictu...           1  \n",
       "2                                     anim write sentenc           0  \n",
       "3      peopl pictur visit london write day london poi...           0  \n",
       "4      time mull wine gluhwein german vin chaud frenc...           2  \n",
       "...                                                  ...         ...  \n",
       "11217                                     battl waterloo           3  \n",
       "11218                                     battl waterloo           3  \n",
       "11219                     read follow articl georg lunch           1  \n",
       "11220                     read follow articl georg lunch           1  \n",
       "11221                     read follow articl georg lunch           1  \n",
       "\n",
       "[11222 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_aspects = pd.merge(df_task_aspects, df_task_topic, on=\"taskId\", how=\"inner\")\n",
    "df_task_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "233219e0-60db-4a76-a57c-31dd06ad0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_aspects = pd.merge(df_task_aspects, df_aspect_topic, on=\"aspectId\", how=\"inner\")\n",
    "# df_task_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03c5f529-4da5-472a-be33-95cb7147343a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_topic</th>\n",
       "      <th>aspect_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_topic  aspect_topic\n",
       "0               0             0\n",
       "1               1             0\n",
       "2               0             2\n",
       "3               0             2\n",
       "4               0             3\n",
       "...           ...           ...\n",
       "11121           1             0\n",
       "11122           1             0\n",
       "11123           2             1\n",
       "11124           2             1\n",
       "11125           2             1\n",
       "\n",
       "[11126 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map = df_task_aspects[[\"task_topic\", \"aspect_topic\"]]\n",
    "df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0631d512-1335-4aa2-95f9-40897a0f983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_topic</th>\n",
       "      <th>aspect_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3, 2, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 1, 3, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_topic  aspect_topic\n",
       "0           0  [0, 2, 3, 1]\n",
       "1           1  [0, 3, 2, 1]\n",
       "2           2  [3, 2, 1, 0]\n",
       "3           3  [2, 1, 3, 0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map.drop_duplicates().groupby(\"task_topic\")[\"aspect_topic\"].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367073c9-fb50-4927-ba10-9ae1eb9ca8fc",
   "metadata": {},
   "source": [
    "Mapping 2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf0344e4-4295-4572-96bf-1651359bed7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspectId</th>\n",
       "      <th>description_x</th>\n",
       "      <th>task_topic</th>\n",
       "      <th>description_y</th>\n",
       "      <th>aspect_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14ambh1obhw7TYMQE8lcC1</td>\n",
       "      <td>9639</td>\n",
       "      <td>write short text sentenc past simpl word usual...</td>\n",
       "      <td>0</td>\n",
       "      <td>word right order</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25RGLvb2p0G5zulfX9xQOj</td>\n",
       "      <td>9639</td>\n",
       "      <td>man woman write sentenc posit neg happen pictu...</td>\n",
       "      <td>1</td>\n",
       "      <td>word right order</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18Ccvc8NMJT5xqLv9nAgTH</td>\n",
       "      <td>9937</td>\n",
       "      <td>anim write sentenc</td>\n",
       "      <td>0</td>\n",
       "      <td>good answer orang utan strong social bond</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4i811yJMsQja4C3GII7BHS</td>\n",
       "      <td>9937</td>\n",
       "      <td>anim write sentenc</td>\n",
       "      <td>0</td>\n",
       "      <td>good answer orang utan strong social bond</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3Jr6T26XL13aKRh31JX0xi</td>\n",
       "      <td>9633</td>\n",
       "      <td>peopl pictur visit london write day london poi...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject verb congruent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>3Djh3SW7P7p7vZe1JVgsyw</td>\n",
       "      <td>381288</td>\n",
       "      <td>climat chang paragraph</td>\n",
       "      <td>1</td>\n",
       "      <td>impact climat chang widespread affect weather ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>68RE5Cw3jm48eggO9ZPAJf</td>\n",
       "      <td>381288</td>\n",
       "      <td>climat chang paragraph</td>\n",
       "      <td>1</td>\n",
       "      <td>impact climat chang widespread affect weather ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>2FRQuUvYy7J6fiChXiS0LC</td>\n",
       "      <td>379209</td>\n",
       "      <td>solv type answer</td>\n",
       "      <td>2</td>\n",
       "      <td>learner appli commut associ properti addit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11124</th>\n",
       "      <td>2Om9QzEpf5raBfTy7yw79q</td>\n",
       "      <td>379209</td>\n",
       "      <td>type miss fact fact famili</td>\n",
       "      <td>2</td>\n",
       "      <td>learner appli commut associ properti addit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11125</th>\n",
       "      <td>1vmTwnxXvLHaBpLOllxi8E</td>\n",
       "      <td>379209</td>\n",
       "      <td>look model would part fact famili explain</td>\n",
       "      <td>2</td>\n",
       "      <td>learner appli commut associ properti addit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11126 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       taskId  aspectId  \\\n",
       "0      14ambh1obhw7TYMQE8lcC1      9639   \n",
       "1      25RGLvb2p0G5zulfX9xQOj      9639   \n",
       "2      18Ccvc8NMJT5xqLv9nAgTH      9937   \n",
       "3      4i811yJMsQja4C3GII7BHS      9937   \n",
       "4      3Jr6T26XL13aKRh31JX0xi      9633   \n",
       "...                       ...       ...   \n",
       "11121  3Djh3SW7P7p7vZe1JVgsyw    381288   \n",
       "11122  68RE5Cw3jm48eggO9ZPAJf    381288   \n",
       "11123  2FRQuUvYy7J6fiChXiS0LC    379209   \n",
       "11124  2Om9QzEpf5raBfTy7yw79q    379209   \n",
       "11125  1vmTwnxXvLHaBpLOllxi8E    379209   \n",
       "\n",
       "                                           description_x  task_topic  \\\n",
       "0      write short text sentenc past simpl word usual...           0   \n",
       "1      man woman write sentenc posit neg happen pictu...           1   \n",
       "2                                     anim write sentenc           0   \n",
       "3                                     anim write sentenc           0   \n",
       "4      peopl pictur visit london write day london poi...           0   \n",
       "...                                                  ...         ...   \n",
       "11121                             climat chang paragraph           1   \n",
       "11122                             climat chang paragraph           1   \n",
       "11123                                   solv type answer           2   \n",
       "11124                         type miss fact fact famili           2   \n",
       "11125          look model would part fact famili explain           2   \n",
       "\n",
       "                                           description_y  aspect_topic  \n",
       "0                                       word right order             0  \n",
       "1                                       word right order             0  \n",
       "2              good answer orang utan strong social bond             2  \n",
       "3              good answer orang utan strong social bond             2  \n",
       "4                                 subject verb congruent             3  \n",
       "...                                                  ...           ...  \n",
       "11121  impact climat chang widespread affect weather ...             0  \n",
       "11122  impact climat chang widespread affect weather ...             0  \n",
       "11123         learner appli commut associ properti addit             1  \n",
       "11124         learner appli commut associ properti addit             1  \n",
       "11125         learner appli commut associ properti addit             1  \n",
       "\n",
       "[11126 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f4634-4941-4e9a-b715-458f5174bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each task, assign the aspect_topics (from the task's aspects), and compute the probabilities of how often would topic i map to aspect_topic j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b5c05007-03a9-486a-8da1-1d106d8083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_task_aspects.groupby([\"task_topic\", \"aspect_topic\"]).count()[[\"taskId\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7e1f98bb-3e7f-4ee5-9d8b-9bf9a43546dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = df_map.groupby(\"task_topic\").count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf2c2b5c-6532-4f0c-87e1-b707b9efa7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.merge(d, d1, on=\"task_topic\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a848b50-e8e0-4951-a5d7-0d0d3885a11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_topic</th>\n",
       "      <th>aspect_topic_x</th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspect_topic_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1143</td>\n",
       "      <td>5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1853</td>\n",
       "      <td>5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1252</td>\n",
       "      <td>5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>810</td>\n",
       "      <td>5058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task_topic  aspect_topic_x  taskId  aspect_topic_y\n",
       "0           0               0    1143            5058\n",
       "1           0               1    1853            5058\n",
       "2           0               2    1252            5058\n",
       "3           0               3     810            5058\n",
       "4           1               0    1351            5101"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1f1b14ac-bea8-4332-9036-343a5d680347",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[\"probability\"] = r[\"taskId\"] / r[\"aspect_topic_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "86a84876-2868-410a-a6f8-9f48f3a02666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_topic</th>\n",
       "      <th>aspect_topic_x</th>\n",
       "      <th>taskId</th>\n",
       "      <th>aspect_topic_y</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1143</td>\n",
       "      <td>5058</td>\n",
       "      <td>0.225979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1853</td>\n",
       "      <td>5058</td>\n",
       "      <td>0.366350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1252</td>\n",
       "      <td>5058</td>\n",
       "      <td>0.247529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>810</td>\n",
       "      <td>5058</td>\n",
       "      <td>0.160142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5101</td>\n",
       "      <td>0.264850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1711</td>\n",
       "      <td>5101</td>\n",
       "      <td>0.335424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1363</td>\n",
       "      <td>5101</td>\n",
       "      <td>0.267203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>676</td>\n",
       "      <td>5101</td>\n",
       "      <td>0.132523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>840</td>\n",
       "      <td>0.177381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>312</td>\n",
       "      <td>840</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>338</td>\n",
       "      <td>840</td>\n",
       "      <td>0.402381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>840</td>\n",
       "      <td>0.048810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>127</td>\n",
       "      <td>0.102362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>0.417323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>127</td>\n",
       "      <td>0.417323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>127</td>\n",
       "      <td>0.062992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_topic  aspect_topic_x  taskId  aspect_topic_y  probability\n",
       "0            0               0    1143            5058     0.225979\n",
       "1            0               1    1853            5058     0.366350\n",
       "2            0               2    1252            5058     0.247529\n",
       "3            0               3     810            5058     0.160142\n",
       "4            1               0    1351            5101     0.264850\n",
       "5            1               1    1711            5101     0.335424\n",
       "6            1               2    1363            5101     0.267203\n",
       "7            1               3     676            5101     0.132523\n",
       "8            2               0     149             840     0.177381\n",
       "9            2               1     312             840     0.371429\n",
       "10           2               2     338             840     0.402381\n",
       "11           2               3      41             840     0.048810\n",
       "12           3               0      13             127     0.102362\n",
       "13           3               1      53             127     0.417323\n",
       "14           3               2      53             127     0.417323\n",
       "15           3               3       8             127     0.062992"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d913a3-4878-4f2e-af0c-074e90ccfe8b",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce47dcb-bb43-4b1c-a824-78b7c4484739",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/final_tasks_DE.csv\")\n",
    "stop_words = stopwords.words('german')\n",
    "df.dropna(subset=[\"description\"], inplace=True)\n",
    "data = df[\"description\"].to_list() \n",
    "num_topics = 10\n",
    "tfidf_vectorizer, svd, normalizer, lsa_output = lsa(data, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94d867-31d9-4f83-8235-8e716d403fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Topic 1: englisch | horst | schreib | horen | schreiben\", \n",
    "    \"Topic 2: satz | schreib | prateritum | hideaway | passiv\", \n",
    "    \"Topic 3: horen | schreiben | englisch | satz | passiv\", \n",
    "    \"Topic 4: massachusett | institut | technolog | of | infinitiv\", \n",
    "    \"Topic 5: infinitiv | komma | denk | prateritum | zubird\", \n",
    "    \"Topic 6: prateritum | hideaway | hideout | hauptsatz | relativsatz\", \n",
    "    \"Topic 7: frage | indirekt | direkt | zwei | hauptsatz\", \n",
    "    \"Topic 8: hauptsatz | zwei | satzen | relativsatz | schreib\", \n",
    "    \"Topic 9: lair | prateritum | frage | satz | schreib\", \n",
    "    \"Topic 10: frage | indirekt | direkt | schreib | passiv\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4332a76-a3fa-40a5-94e1-71770284ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = df.loc[1101, \"description\"]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe80557-7f30-47ba-86f9-155111db2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"It's a question of going to Edinburgh in the time of earthquake.\"\n",
    "\n",
    "# Transform test text to LSA space\n",
    "test_text_lsa_normalized = transform_text(test_text, tfidf_vectorizer, svd, normalizer)\n",
    "\n",
    "# Transform topics to LSA space\n",
    "list_topics_normalized = []\n",
    "for topic in topics:\n",
    "    list_topics_normalized.append(transform_text(topic, tfidf_vectorizer, svd, normalizer)[0].tolist())\n",
    "    topics_lsa_normalized = np.array(list_topics_normalized)\n",
    "    \n",
    "# Assign topic to test text\n",
    "most_similar_topic_index = assign_topic_to_text(test_text_lsa_normalized, topics_lsa_normalized)\n",
    "\n",
    "print(f\"{topics[most_similar_topic_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3f9cd8-72fe-4383-9e26-80dc5af7389d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbdaa0-e29c-4e2a-99bf-44c9b91dc16f",
   "metadata": {},
   "source": [
    "> the LSA output is a matrix where each row represents a document and each column represents a topic. Each value indicates the strength of the association between the document and the topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb_venv",
   "language": "python",
   "name": "tb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
