{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d351f9e-d4fc-4c4d-92ff-a0d3c8543d20",
   "metadata": {},
   "source": [
    "This notebook is for preliminary steps of text preprocessing: stopwords removal, lowering case, lemmatization.. <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00c7f70-393c-4e3e-9a26-3809941a16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4027f5c4-48a6-448b-9cb0-d00064ee031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tools(language, stopwords=stopwords):\n",
    "    \"\"\"\n",
    "    Load open tasks in DataFrame from csv file.\n",
    "    Define stopwords and lemmatizer appropriate to given language of data.\n",
    "    \"\"\"\n",
    "    if language == \"german\": \n",
    "        stopwords = stopwords.words('german') \n",
    "        lemmatizer = spacy.load(\"de_core_news_sm\") \n",
    "    elif language == \"english\": \n",
    "        stopwords = stopwords.words('english')\n",
    "        lemmatizer = spacy.load('en_core_web_sm')\n",
    "    else:\n",
    "        raise language + \" language not supported.\" \n",
    "    return stopwords, lemmatizer \n",
    "\n",
    "def preprocess(text, lemmatizer, stopwords, stemmer=stemmer):\n",
    "    if isinstance(text, float):\n",
    "        return \"\"\n",
    "    # lowercase, remove punctuation, tokenize \n",
    "    words = simple_preprocess(text, deacc=True, min_len=1, max_len=50)\n",
    "    # remove stopwords \n",
    "    tokens = [word for word in words if word not in stopwords]\n",
    "    # stemming\n",
    "    stems = [stemmer.stem(token) for token in tokens]\n",
    "    # lemmatize\n",
    "    stemmed_doc = lemmatizer(\" \".join(stems))\n",
    "    lemmas = [s.lemma_ for s in stemmed_doc]\n",
    "    # lowercase again (apparently stemming capitalizes the output) \n",
    "    lemmas = [lemma.lower() for lemma in lemmas] \n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049c92a-7712-4e40-a842-e278c769f40d",
   "metadata": {},
   "source": [
    "**Tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d3faf9-2a70-44de-931f-05e8c6b6a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords, lemmatizer = load_tools(\"english\")\n",
    "filenames = [\n",
    "    \"open_tasks_EN\",\n",
    "    \"augmented_BT_EN\", \n",
    "    \"augmented_RD_EN\", \n",
    "    \"augmented_RI_EN\", \n",
    "    \"augmented_RS_EN\", \n",
    "    \"augmented_SR_EN\", \n",
    "]\n",
    "\n",
    "for filename in filenames: \n",
    "    df = pd.read_csv(\"data/\"+filename+\".csv\") \n",
    "    df[\"description\"] = df[\"description\"].apply(lambda text: preprocess(text, lemmatizer, stopwords))\n",
    "    df[\"word_count\"] = df[\"description\"].apply(lambda s: len(s.split())) \n",
    "    df.to_csv(\"data/preprocessed_\"+filename+\".csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cf06a8-7a5a-41b2-99b8-bb6b9f9f60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords, lemmatizer = load_tools(\"german\")\n",
    "filenames = [\n",
    "    \"open_tasks_DE\",\n",
    "    \"augmented_BT_DE\", \n",
    "    \"augmented_RD_DE\", \n",
    "    \"augmented_RI_DE\", \n",
    "    \"augmented_RS_DE\", \n",
    "    \"augmented_SR_DE\", \n",
    "]\n",
    "\n",
    "for filename in filenames: \n",
    "    df = pd.read_csv(\"data/\"+filename+\".csv\") \n",
    "    df[\"description\"] = df[\"description\"].apply(lambda text: preprocess(text, lemmatizer, stopwords))\n",
    "    df[\"word_count\"] = df[\"description\"].apply(lambda s: len(s.split())) \n",
    "    df.to_csv(\"data/preprocessed_\"+filename+\".csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3cd65-13b4-4ffe-b5d6-bab6d79f0064",
   "metadata": {},
   "source": [
    "**Aspects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa59a335-b34e-4444-85a2-7c7da4d7cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords, lemmatizer = load_tools(\"english\")\n",
    "filename = \"concept_aspects_EN\"\n",
    "\n",
    "df = pd.read_csv(\"data/\"+filename+\".csv\") \n",
    "df[\"description\"] = df[\"description\"].apply(lambda text: preprocess(text, lemmatizer, stopwords))\n",
    "df[\"word_count\"] = df[\"description\"].apply(lambda s: len(s.split())) \n",
    "df.to_csv(\"data/preprocessed_\"+filename+\".csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3d8c79-b61b-4571-bca5-b31b942060b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords, lemmatizer = load_tools(\"german\")\n",
    "filename = \"concept_aspects_DE\"\n",
    "\n",
    "df = pd.read_csv(\"data/\"+filename+\".csv\") \n",
    "df[\"description\"] = df[\"description\"].apply(lambda text: preprocess(text, lemmatizer, stopwords))\n",
    "df[\"word_count\"] = df[\"description\"].apply(lambda s: len(s.split())) \n",
    "df.to_csv(\"data/preprocessed_\"+filename+\".csv\", index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c949d58d-df5c-4a79-9e53-f8353771bae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspectId</th>\n",
       "      <th>description</th>\n",
       "      <th>type</th>\n",
       "      <th>groupId</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9639</td>\n",
       "      <td>word right order</td>\n",
       "      <td>CONCEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9937</td>\n",
       "      <td>good answer orang utan strong social bond</td>\n",
       "      <td>CONCEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9633</td>\n",
       "      <td>subject verb congruent</td>\n",
       "      <td>CONCEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11401</td>\n",
       "      <td>answer mention keyword look correctstat</td>\n",
       "      <td>CONCEPT</td>\n",
       "      <td>55122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9984</td>\n",
       "      <td>verb conjug expect ten expectedten</td>\n",
       "      <td>CONCEPT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aspectId                                description     type  groupId  \\\n",
       "0      9639                           word right order  CONCEPT      NaN   \n",
       "1      9937  good answer orang utan strong social bond  CONCEPT      NaN   \n",
       "2      9633                     subject verb congruent  CONCEPT      NaN   \n",
       "3     11401    answer mention keyword look correctstat  CONCEPT  55122.0   \n",
       "4      9984         verb conjug expect ten expectedten  CONCEPT      NaN   \n",
       "\n",
       "   categoryId  word_count  \n",
       "0         NaN           3  \n",
       "1         NaN           7  \n",
       "2         NaN           3  \n",
       "3         NaN           5  \n",
       "4         NaN           5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/preprocessed_concept_aspects_EN.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d928fc-9632-4f27-968a-e9aa906dc401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb_venv",
   "language": "python",
   "name": "tb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
