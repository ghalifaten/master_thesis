{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685c647c-afba-4286-825b-5d5591517376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497f9f35-aa91-4ba8-b245-114253f6805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/open_tasks_Corn_EKV_DE.csv\")\n",
    "data = df[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d716ea9-e418-4804-aac0-7fadb2b094e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "\n",
    "# Load the German language model\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "def preprocess_data(text): \n",
    " # lowercase, tokenize, and remove stopwords\n",
    "    doc = nlp(text)\n",
    "    verbs = [token.text.lower() for token in doc if token.pos_ == \"VERB\"]\n",
    "    preprocessed_text = simple_preprocess(text)\n",
    "    words_list = [word for word in preprocessed_text if word not in verbs and word not in stop_words]\n",
    "    return \" \".join(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2772e898-b328-476c-bc75-9d8b0caa8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = data.apply(preprocess_data).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7fcf97f-ea20-4e94-bc10-9776ed7b78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_semantic_analysis(texts, num_topics=5):\n",
    "    # Step 1: Convert texts to TF-IDF matrix\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=1, stop_words=None)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # Step 2: Apply Singular Value Decomposition (SVD)\n",
    "    svd = TruncatedSVD(n_components=num_topics)\n",
    "    latent_semantic_analysis = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    # Step 3: Normalize the output of SVD\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    latent_semantic_analysis = normalizer.fit_transform(latent_semantic_analysis)\n",
    "    \n",
    "    # Step 4: Print the topics and their most relevant terms\n",
    "    terms = tfidf_vectorizer.get_feature_names_out()\n",
    "    for i, topic in enumerate(svd.components_):\n",
    "        top_terms_idx = topic.argsort()[:-6:-1] # Top 5 terms\n",
    "        top_terms = [terms[idx] for idx in top_terms_idx]\n",
    "        print(f\"Topic {i+1}: {' | '.join(top_terms)}\")\n",
    "    \n",
    "    return tfidf_vectorizer, svd, normalizer, latent_semantic_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7841058a-3bd2-4d8e-8b53-4dfdf25b34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: passiv | präsens | satz | ergänze | schreibe\n",
      "Topic 2: geschwindigkeit | nenne | elektrischen | km | auto\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, svd, normalizer, lsa_output = latent_semantic_analysis(preprocessed_data, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbdaa0-e29c-4e2a-99bf-44c9b91dc16f",
   "metadata": {},
   "source": [
    "> the LSA output is a matrix where each row represents a document and each column represents a topic. Each value indicates the strength of the association between the document and the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7c0615-dcd6-4a8b-aca6-ddd2f93de9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"LSA Output:\")\n",
    "# print(lsa_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b0054-5a41-4111-aa5d-afc2d85ea6ad",
   "metadata": {},
   "source": [
    "Assign a given text to a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5daf31b5-d978-4327-914c-300c8d3225e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def preprocess_text(texts):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=1, stop_words=None)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "    return tfidf_vectorizer, tfidf_matrix\n",
    "\n",
    "def transform_text(text, tfidf_vectorizer, svd, normalizer):\n",
    "    text_tfidf = tfidf_vectorizer.transform([text])\n",
    "    text_lsa = svd.transform(text_tfidf)\n",
    "    text_lsa_normalized = normalizer.transform(text_lsa)\n",
    "    return text_lsa_normalized\n",
    "\n",
    "def assign_topic_to_text(text_lsa_normalized, topics_lsa_normalized):\n",
    "    similarities = cosine_similarity(text_lsa_normalized, topics_lsa_normalized)\n",
    "    most_similar_topic_index = np.argmax(similarities)\n",
    "    return most_similar_topic_index\n",
    "\n",
    "# Example usage:\n",
    "texts = preprocessed_data\n",
    "\n",
    "topics = [\n",
    "    \"Topic 1: grammatik präsens passiv satz ergänze schreibe\",\n",
    "    \"Topic 2: physik geschwindigkeit nenne elektrischen km auto\",\n",
    "]\n",
    "\n",
    "# Preprocess texts and topics\n",
    "tfidf_vectorizer, tfidf_matrix = preprocess_text(texts)\n",
    "\n",
    "# Perform LSA\n",
    "svd = TruncatedSVD(n_components=len(topics))\n",
    "lsa = svd.fit_transform(tfidf_matrix)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa_normalized = normalizer.fit_transform(lsa)\n",
    "\n",
    "# Transform topics to LSA space\n",
    "list_topics_normalized = []\n",
    "for topic in topics:\n",
    "    list_topics_normalized.append(transform_text(topic, tfidf_vectorizer, svd, normalizer)[0].tolist())\n",
    "    topics_lsa_normalized = np.array(list_topics_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b8b55b-7bdb-4db8-9047-ca914b08085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 2: physik geschwindigkeit nenne elektrischen km auto\n"
     ]
    }
   ],
   "source": [
    "# Test text\n",
    "test_text = \"berechnen Sie die Strecke, die das Auto in einer Stunde bei einer Geschwindigkeit von 100 km pro Stunde zurücklegt.\"\n",
    "\n",
    "# Transform test text to LSA space\n",
    "test_text_lsa_normalized = transform_text(test_text, tfidf_vectorizer, svd, normalizer)\n",
    "\n",
    "# Assign topic to test text\n",
    "most_similar_topic_index = assign_topic_to_text(test_text_lsa_normalized, topics_lsa_normalized)\n",
    "\n",
    "print(f\"{topics[most_similar_topic_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83c33204-c8d5-4fde-baad-15458aabc868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: grammatik präsens passiv satz ergänze schreibe\n"
     ]
    }
   ],
   "source": [
    "# Test text\n",
    "test_text = \"einen Satz im Präsens mit dem Verb essen schreiben\"\n",
    "\n",
    "# Transform test text to LSA space\n",
    "test_text_lsa_normalized = transform_text(test_text, tfidf_vectorizer, svd, normalizer)\n",
    "\n",
    "# Assign topic to test text\n",
    "most_similar_topic_index = assign_topic_to_text(test_text_lsa_normalized, topics_lsa_normalized)\n",
    "\n",
    "print(f\"{topics[most_similar_topic_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad650ba1-6cbb-4628-bc97-f5a13100d0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb_venv",
   "language": "python",
   "name": "tb_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
